{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "741268e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "# 라이브러리 설치\n",
    "# ===============================================\n",
    "# 필요한 패키지 설치 (최초 1회만 실행)\n",
    "!pip install -q langchain\n",
    "!pip install -q langchain-community\n",
    "!pip install -q langchain-openai\n",
    "!pip install -q pypdf\n",
    "!pip install -q pymupdf\n",
    "!pip install -q chromadb\n",
    "!pip install -q tiktoken\n",
    "!pip install -q sentence-transformers\n",
    "!pip install -q rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0d57a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 라이브러리 임포트 완료\n"
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "# 셀 3: 라이브러리 임포트\n",
    "# ===============================================\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "from datetime import datetime\n",
    "\n",
    "# LangChain 핵심 모듈\n",
    "from langchain.document_loaders import PyPDFLoader, PyMuPDFLoader\n",
    "from langchain.text_splitter import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    CharacterTextSplitter,\n",
    "    TokenTextSplitter,\n",
    ")\n",
    "from langchain.embeddings import OpenAIEmbeddings, HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.schema import Document\n",
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"모든 라이브러리 임포트 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d967ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF 경로: D:\\data\n",
      "벡터 DB 저장 경로: D:\\data\\chroma_db\n"
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "# 셀 4: 경로 설정\n",
    "# ===============================================\n",
    "# 파일 경로 설정\n",
    "PDF_PATH = r\"D:\\data\"  # PDF 파일이 있는 폴더\n",
    "PERSIST_DIRECTORY = r\"D:\\data\\chroma_db\"  # 벡터 DB 저장 경로\n",
    "\n",
    "print(f\"PDF 경로: {PDF_PATH}\")\n",
    "print(f\"벡터 DB 저장 경로: {PERSIST_DIRECTORY}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fbe4aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모든 함수 정의 완료\n"
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "# 셀 5: 모든 함수 정의\n",
    "# ===============================================\n",
    "\n",
    "\n",
    "def load_pdf_documents_improved(directory_path: str) -> List[Document]:\n",
    "    \"\"\"\n",
    "    한국어 의료 문서에 최적화된 PDF 로딩\n",
    "    \"\"\"\n",
    "    print(f\"PDF 파일 로드 중: {directory_path}\")\n",
    "\n",
    "    pdf_files = list(Path(directory_path).glob(\"*.pdf\"))\n",
    "\n",
    "    if not pdf_files:\n",
    "        print(\"PDF 파일을 찾을 수 없습니다!\")\n",
    "        return []\n",
    "\n",
    "    all_docs = []\n",
    "\n",
    "    for pdf_file in pdf_files[:2]:  # 2개만 로드\n",
    "        print(f\"  로딩 중: {pdf_file.name}\")\n",
    "\n",
    "        # PyMuPDF 로더 사용 (한국어 처리 개선)\n",
    "        loader = PyMuPDFLoader(str(pdf_file))\n",
    "        docs = loader.load()\n",
    "\n",
    "        # 문서 전처리\n",
    "        for doc in docs:\n",
    "            # 메타데이터 추가\n",
    "            doc.metadata[\"source\"] = pdf_file.name\n",
    "            doc.metadata[\"file_path\"] = str(pdf_file)\n",
    "\n",
    "            # 텍스트 정리\n",
    "            content = doc.page_content\n",
    "            content = re.sub(r\"\\s+\", \" \", content)\n",
    "            content = re.sub(r\"-\\s*\\d+\\s*-\", \"\", content)\n",
    "            content = re.sub(r\"\\n\\s*\\n\", \"\\n\", content)\n",
    "\n",
    "            doc.page_content = content.strip()\n",
    "\n",
    "        all_docs.extend(docs)\n",
    "\n",
    "    print(f\"총 {len(all_docs)}개 페이지 로드 완료\")\n",
    "    return all_docs\n",
    "\n",
    "\n",
    "def create_korean_optimized_chunks(\n",
    "    documents: List[Document],\n",
    ") -> Dict[str, List[Document]]:\n",
    "    \"\"\"\n",
    "    한국어 의료 문서에 최적화된 여러 청킹 전략 비교\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "\n",
    "    # 전략 1: 한국어 특화 RecursiveCharacterTextSplitter\n",
    "    print(\"\\n텍스트 분할 방법 1: 한국어 최적화 RecursiveCharacterTextSplitter\")\n",
    "    korean_separators = [\n",
    "        \"\\n\\n\",  # 단락\n",
    "        \"\\n\",  # 줄바꿈\n",
    "        \"다.\",  # 한국어 문장 종결\n",
    "        \"요.\",\n",
    "        \"함.\",\n",
    "        \". \",  # 영문 문장\n",
    "        \")\",  # 번호 목록\n",
    "        \" \",  # 공백\n",
    "        \"\",\n",
    "    ]\n",
    "\n",
    "    korean_recursive_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500,\n",
    "        chunk_overlap=100,\n",
    "        separators=korean_separators,\n",
    "        length_function=len,\n",
    "    )\n",
    "    results[\"korean_recursive\"] = korean_recursive_splitter.split_documents(documents)\n",
    "    print(f\"  - 생성된 청크 수: {len(results['korean_recursive'])}\")\n",
    "\n",
    "    # 전략 2: 기본 RecursiveCharacterTextSplitter\n",
    "    print(\"\\n텍스트 분할 방법 2: 기본 RecursiveCharacterTextSplitter\")\n",
    "    basic_recursive_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=500, chunk_overlap=100, length_function=len\n",
    "    )\n",
    "    results[\"basic_recursive\"] = basic_recursive_splitter.split_documents(documents)\n",
    "    print(f\"  - 생성된 청크 수: {len(results['basic_recursive'])}\")\n",
    "\n",
    "    # 전략 3: CharacterTextSplitter\n",
    "    print(\"\\n텍스트 분할 방법 3: CharacterTextSplitter\")\n",
    "    character_splitter = CharacterTextSplitter(\n",
    "        chunk_size=500, chunk_overlap=100, separator=\"\\n\"\n",
    "    )\n",
    "    results[\"character\"] = character_splitter.split_documents(documents)\n",
    "    print(f\"  - 생성된 청크 수: {len(results['character'])}\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def add_medical_metadata(chunks: List[Document]) -> List[Document]:\n",
    "    \"\"\"\n",
    "    의료 문서 청크에 섹션 메타데이터 추가\n",
    "    \"\"\"\n",
    "    print(\"\\n메타데이터 추가 중...\")\n",
    "\n",
    "    for chunk in chunks:\n",
    "        content = chunk.page_content.lower()\n",
    "\n",
    "        # 섹션 자동 분류\n",
    "        if any(keyword in content for keyword in [\"진단\", \"검사\", \"기준\"]):\n",
    "            chunk.metadata[\"section\"] = \"diagnosis\"\n",
    "            chunk.metadata[\"section_kr\"] = \"진단\"\n",
    "        elif any(keyword in content for keyword in [\"운동\", \"신체활동\", \"활동\"]):\n",
    "            chunk.metadata[\"section\"] = \"exercise\"\n",
    "            chunk.metadata[\"section_kr\"] = \"운동요법\"\n",
    "        elif any(keyword in content for keyword in [\"약물\", \"치료\", \"처방\"]):\n",
    "            chunk.metadata[\"section\"] = \"treatment\"\n",
    "            chunk.metadata[\"section_kr\"] = \"치료\"\n",
    "        elif any(keyword in content for keyword in [\"합병증\", \"부작용\"]):\n",
    "            chunk.metadata[\"section\"] = \"complications\"\n",
    "            chunk.metadata[\"section_kr\"] = \"합병증\"\n",
    "        elif any(keyword in content for keyword in [\"식이\", \"영양\", \"식사\"]):\n",
    "            chunk.metadata[\"section\"] = \"diet\"\n",
    "            chunk.metadata[\"section_kr\"] = \"식이요법\"\n",
    "        else:\n",
    "            chunk.metadata[\"section\"] = \"general\"\n",
    "            chunk.metadata[\"section_kr\"] = \"일반\"\n",
    "\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def get_embedding_model(model_type: str = \"korean\"):\n",
    "    \"\"\"\n",
    "    임베딩 모델 선택 (한국어/다국어/OpenAI)\n",
    "    \"\"\"\n",
    "    if model_type == \"korean\":\n",
    "        print(\"한국어 특화 임베딩 모델 로딩 중...\")\n",
    "        return HuggingFaceEmbeddings(\n",
    "            model_name=\"jhgan/ko-sroberta-multitask\",\n",
    "            model_kwargs={\"device\": \"cpu\"},\n",
    "            encode_kwargs={\"normalize_embeddings\": True},\n",
    "        )\n",
    "    elif model_type == \"multilingual\":\n",
    "        print(\"다국어 임베딩 모델 로딩 중...\")\n",
    "        return HuggingFaceEmbeddings(\n",
    "            model_name=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\",\n",
    "            model_kwargs={\"device\": \"cpu\"},\n",
    "            encode_kwargs={\"normalize_embeddings\": True},\n",
    "        )\n",
    "    else:  # openai\n",
    "        print(\"OpenAI 임베딩 모델 사용\")\n",
    "        return OpenAIEmbeddings(model=\"text-embedding-ada-002\", chunk_size=100)\n",
    "\n",
    "\n",
    "def create_vectorstore_safe(\n",
    "    chunks: List[Document], embeddings, persist_dir: str, batch_size: int = 50\n",
    "):\n",
    "    \"\"\"\n",
    "    안전한 벡터 DB 생성 (큰 문서도 처리 가능)\n",
    "    \"\"\"\n",
    "    print(f\"\\n벡터 DB 생성 중 (총 {len(chunks)}개 청크)...\")\n",
    "\n",
    "    if len(chunks) > 200:\n",
    "        print(f\"청크가 많아 배치 처리를 사용합니다 (배치 크기: {batch_size})\")\n",
    "\n",
    "        vectorstore = None\n",
    "        for i in range(0, len(chunks), batch_size):\n",
    "            batch = chunks[i : i + batch_size]\n",
    "            batch_end = min(i + batch_size, len(chunks))\n",
    "            print(f\"  처리 중: {i+1}-{batch_end}/{len(chunks)}\")\n",
    "\n",
    "            if vectorstore is None:\n",
    "                vectorstore = Chroma.from_documents(\n",
    "                    documents=batch,\n",
    "                    embedding=embeddings,\n",
    "                    persist_directory=persist_dir,\n",
    "                    collection_metadata={\"hnsw:space\": \"cosine\"},\n",
    "                )\n",
    "            else:\n",
    "                vectorstore.add_documents(batch)\n",
    "\n",
    "            if i + batch_size < len(chunks):\n",
    "                time.sleep(0.5)\n",
    "    else:\n",
    "        vectorstore = Chroma.from_documents(\n",
    "            documents=chunks,\n",
    "            embedding=embeddings,\n",
    "            persist_directory=persist_dir,\n",
    "            collection_metadata={\"hnsw:space\": \"cosine\"},\n",
    "        )\n",
    "\n",
    "    vectorstore.persist()\n",
    "    print(\"벡터 DB 저장 완료\")\n",
    "    return vectorstore\n",
    "\n",
    "\n",
    "def interpret_chroma_score(distance):\n",
    "    \"\"\"\n",
    "    Chroma 거리 점수를 유사도로 변환하고 해석\n",
    "\n",
    "    중요: Chroma는 거리(distance)를 반환하므로 낮을수록 좋음!\n",
    "    \"\"\"\n",
    "    similarity_percent = (1 - distance / 2) * 100 if distance < 2 else 0\n",
    "\n",
    "    if distance < 0.3:\n",
    "        quality = \"매우 좋음\"\n",
    "    elif distance < 0.5:\n",
    "        quality = \"좋음\"\n",
    "    elif distance < 0.7:\n",
    "        quality = \"보통\"\n",
    "    elif distance < 1.0:\n",
    "        quality = \"낮음\"\n",
    "    else:\n",
    "        quality = \"매우 낮음\"\n",
    "\n",
    "    return f\"\"\"\n",
    "    거리 점수: {distance:.3f}\n",
    "    유사도: {similarity_percent:.1f}%\n",
    "    품질: {quality}\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "def evaluate_search_quality(vectorstore, test_queries: List[str]):\n",
    "    \"\"\"\n",
    "    검색 품질 평가 및 점수 해석\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"검색 품질 평가\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for query in test_queries:\n",
    "        print(f\"\\n질문: {query}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        # 벡터 검색\n",
    "        vector_results = vectorstore.similarity_search_with_score(query, k=3)\n",
    "\n",
    "        for i, (doc, score) in enumerate(vector_results, 1):\n",
    "            print(f\"\\n  결과 {i}:\")\n",
    "            print(interpret_chroma_score(score))\n",
    "            print(f\"    섹션: {doc.metadata.get('section_kr', 'N/A')}\")\n",
    "            print(f\"    내용: {doc.page_content[:150]}...\")\n",
    "\n",
    "        # MMR 검색\n",
    "        print(\"\\n  [MMR 검색 - 다양성 확보]\")\n",
    "        mmr_results = vectorstore.max_marginal_relevance_search(query, k=3)\n",
    "        for i, doc in enumerate(mmr_results, 1):\n",
    "            print(\n",
    "                f\"    {i}. [{doc.metadata.get('section_kr', 'N/A')}] {doc.page_content[:80]}...\"\n",
    "            )\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                \"query\": query,\n",
    "                \"top_score\": vector_results[0][1] if vector_results else None,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"모든 함수 정의 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c61d657c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 1] PDF 문서 로드\n",
      "PDF 파일 로드 중: D:\\data\n",
      "  로딩 중: 2023 당뇨병 진료지침_전문_240620.pdf\n",
      "총 428개 페이지 로드 완료\n",
      "\n",
      "로드 완료:\n",
      "  - 총 페이지 수: 428\n",
      "  - 첫 페이지 미리보기:\n",
      "    1 Clinical Practice Guidelines for Diabetes...\n"
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "# 셀 6: Step 1 - PDF 문서 로드\n",
    "# ===============================================\n",
    "print(\"\\n[Step 1] PDF 문서 로드\")\n",
    "documents = load_pdf_documents_improved(PDF_PATH)\n",
    "\n",
    "if documents:\n",
    "    print(f\"\\n로드 완료:\")\n",
    "    print(f\"  - 총 페이지 수: {len(documents)}\")\n",
    "    print(f\"  - 첫 페이지 미리보기:\")\n",
    "    print(f\"    {documents[0].page_content[:300]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03fe523c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 2] 테스트 쿼리 정의\n",
      "  1. 이 문서의 주요 내용은 무엇인가요?\n",
      "  2. 당뇨병의 진단기준에 대해 알려주세요.\n",
      "  3. 당뇨병의 운동요법은 어떤것이 있나요?\n"
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "# 셀 7: Step 2 - 테스트 쿼리 정의\n",
    "# ===============================================\n",
    "print(\"\\n[Step 2] 테스트 쿼리 정의\")\n",
    "test_queries = [\n",
    "    \"이 문서의 주요 내용은 무엇인가요?\",\n",
    "    \"당뇨병의 진단기준에 대해 알려주세요.\",\n",
    "    \"당뇨병의 운동요법은 어떤것이 있나요?\",\n",
    "]\n",
    "\n",
    "for i, query in enumerate(test_queries, 1):\n",
    "    print(f\"  {i}. {query}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4388e0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 3] 임베딩 모델 로드\n",
      "한국어 특화 임베딩 모델 로딩 중...\n",
      "임베딩 모델 로드 완료: korean\n"
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "# 셀 8: Step 3 - 임베딩 모델 로드\n",
    "# ===============================================\n",
    "print(\"\\n[Step 3] 임베딩 모델 로드\")\n",
    "EMBEDDING_TYPE = \"korean\"  # korean / multilingual / openai\n",
    "embeddings = get_embedding_model(EMBEDDING_TYPE)\n",
    "print(f\"임베딩 모델 로드 완료: {EMBEDDING_TYPE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a533d71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 4] 청킹 전략 비교\n",
      "\n",
      "텍스트 분할 방법 1: 한국어 최적화 RecursiveCharacterTextSplitter\n",
      "  - 생성된 청크 수: 22\n",
      "\n",
      "텍스트 분할 방법 2: 기본 RecursiveCharacterTextSplitter\n",
      "  - 생성된 청크 수: 21\n",
      "\n",
      "텍스트 분할 방법 3: CharacterTextSplitter\n",
      "  - 생성된 청크 수: 10\n",
      "\n",
      "청킹 전략 비교 결과:\n",
      "  korean_recursive: 22개 청크, 평균 357자\n",
      "  basic_recursive: 21개 청크, 평균 394자\n",
      "  character: 10개 청크, 평균 720자\n",
      "\n",
      "선택된 전략: korean_recursive\n"
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "# 셀 9: Step 4 - 청킹 전략 비교\n",
    "# ===============================================\n",
    "print(\"\\n[Step 4] 청킹 전략 비교\")\n",
    "chunk_strategies = create_korean_optimized_chunks(documents[:10])  # 샘플로 테스트\n",
    "\n",
    "print(\"\\n청킹 전략 비교 결과:\")\n",
    "for name, chunks in chunk_strategies.items():\n",
    "    avg_size = sum(len(c.page_content) for c in chunks) / len(chunks) if chunks else 0\n",
    "    print(f\"  {name}: {len(chunks)}개 청크, 평균 {avg_size:.0f}자\")\n",
    "\n",
    "# 최적 전략 선택\n",
    "best_strategy = \"korean_recursive\"\n",
    "print(f\"\\n선택된 전략: {best_strategy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ef27f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 5] 전체 문서 청킹\n",
      "\n",
      "텍스트 분할 방법 1: 한국어 최적화 RecursiveCharacterTextSplitter\n",
      "  - 생성된 청크 수: 1736\n",
      "\n",
      "텍스트 분할 방법 2: 기본 RecursiveCharacterTextSplitter\n",
      "  - 생성된 청크 수: 1638\n",
      "\n",
      "텍스트 분할 방법 3: CharacterTextSplitter\n",
      "  - 생성된 청크 수: 428\n",
      "전체 문서 청킹 완료:\n",
      "  - 총 청크 수: 1736\n",
      "  - 평균 청크 크기: 373자\n"
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "# 셀 10: Step 5 - 전체 문서 청킹\n",
    "# ===============================================\n",
    "print(\"\\n[Step 5] 전체 문서 청킹\")\n",
    "chunk_strategies_full = create_korean_optimized_chunks(documents)\n",
    "chunks = chunk_strategies_full[best_strategy]\n",
    "\n",
    "print(f\"전체 문서 청킹 완료:\")\n",
    "print(f\"  - 총 청크 수: {len(chunks)}\")\n",
    "print(\n",
    "    f\"  - 평균 청크 크기: {sum(len(c.page_content) for c in chunks) / len(chunks):.0f}자\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b757f51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 6] 메타데이터 추가\n",
      "\n",
      "메타데이터 추가 중...\n",
      "섹션별 청크 분포:\n",
      "  일반: 999개 (57.5%)\n",
      "  치료: 287개 (16.5%)\n",
      "  진단: 279개 (16.1%)\n",
      "  운동요법: 82개 (4.7%)\n",
      "  식이요법: 48개 (2.8%)\n",
      "  합병증: 41개 (2.4%)\n"
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "# 셀 11: Step 6 - 메타데이터 추가\n",
    "# ===============================================\n",
    "print(\"\\n[Step 6] 메타데이터 추가\")\n",
    "chunks = add_medical_metadata(chunks)\n",
    "\n",
    "# 섹션 분포 확인\n",
    "section_distribution = {}\n",
    "for chunk in chunks:\n",
    "    section = chunk.metadata.get(\"section_kr\", \"일반\")\n",
    "    section_distribution[section] = section_distribution.get(section, 0) + 1\n",
    "\n",
    "print(\"섹션별 청크 분포:\")\n",
    "for section, count in sorted(\n",
    "    section_distribution.items(), key=lambda x: x[1], reverse=True\n",
    "):\n",
    "    percentage = (count / len(chunks)) * 100\n",
    "    print(f\"  {section}: {count}개 ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b2c7ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 7] 벡터 DB 생성\n",
      "기존 벡터 DB 삭제 완료: D:\\data\\chroma_db\n",
      "\n",
      "[Step 7] 벡터 DB 생성 (새로 시작)\n",
      "\n",
      "벡터 DB 생성 중 (총 1736개 청크)...\n",
      "청크가 많아 배치 처리를 사용합니다 (배치 크기: 50)\n",
      "  처리 중: 1-50/1736\n",
      "  처리 중: 51-100/1736\n",
      "  처리 중: 101-150/1736\n",
      "  처리 중: 151-200/1736\n",
      "  처리 중: 201-250/1736\n",
      "  처리 중: 251-300/1736\n",
      "  처리 중: 301-350/1736\n",
      "  처리 중: 351-400/1736\n",
      "  처리 중: 401-450/1736\n",
      "  처리 중: 451-500/1736\n",
      "  처리 중: 501-550/1736\n",
      "  처리 중: 551-600/1736\n",
      "  처리 중: 601-650/1736\n",
      "  처리 중: 651-700/1736\n",
      "  처리 중: 701-750/1736\n",
      "  처리 중: 751-800/1736\n",
      "  처리 중: 801-850/1736\n",
      "  처리 중: 851-900/1736\n",
      "  처리 중: 901-950/1736\n",
      "  처리 중: 951-1000/1736\n",
      "  처리 중: 1001-1050/1736\n",
      "  처리 중: 1051-1100/1736\n",
      "  처리 중: 1101-1150/1736\n",
      "  처리 중: 1151-1200/1736\n",
      "  처리 중: 1201-1250/1736\n",
      "  처리 중: 1251-1300/1736\n",
      "  처리 중: 1301-1350/1736\n",
      "  처리 중: 1351-1400/1736\n",
      "  처리 중: 1401-1450/1736\n",
      "  처리 중: 1451-1500/1736\n",
      "  처리 중: 1501-1550/1736\n",
      "  처리 중: 1551-1600/1736\n",
      "  처리 중: 1601-1650/1736\n",
      "  처리 중: 1651-1700/1736\n",
      "  처리 중: 1701-1736/1736\n",
      "벡터 DB 저장 완료\n",
      "현재 임베딩 차원: 768\n",
      "\n",
      "벡터 DB 생성 중 (총 1736개 청크)...\n",
      "청크가 많아 배치 처리를 사용합니다 (배치 크기: 50)\n",
      "  처리 중: 1-50/1736\n",
      "  처리 중: 51-100/1736\n",
      "  처리 중: 101-150/1736\n",
      "  처리 중: 151-200/1736\n",
      "  처리 중: 201-250/1736\n",
      "  처리 중: 251-300/1736\n",
      "  처리 중: 301-350/1736\n",
      "  처리 중: 351-400/1736\n",
      "  처리 중: 401-450/1736\n",
      "  처리 중: 451-500/1736\n",
      "  처리 중: 501-550/1736\n",
      "  처리 중: 551-600/1736\n",
      "  처리 중: 601-650/1736\n",
      "  처리 중: 651-700/1736\n",
      "  처리 중: 701-750/1736\n",
      "  처리 중: 751-800/1736\n",
      "  처리 중: 801-850/1736\n",
      "  처리 중: 851-900/1736\n",
      "  처리 중: 901-950/1736\n",
      "  처리 중: 951-1000/1736\n",
      "  처리 중: 1001-1050/1736\n",
      "  처리 중: 1051-1100/1736\n",
      "  처리 중: 1101-1150/1736\n",
      "  처리 중: 1151-1200/1736\n",
      "  처리 중: 1201-1250/1736\n",
      "  처리 중: 1251-1300/1736\n",
      "  처리 중: 1301-1350/1736\n",
      "  처리 중: 1351-1400/1736\n",
      "  처리 중: 1401-1450/1736\n",
      "  처리 중: 1451-1500/1736\n",
      "  처리 중: 1501-1550/1736\n",
      "  처리 중: 1551-1600/1736\n",
      "  처리 중: 1601-1650/1736\n",
      "  처리 중: 1651-1700/1736\n",
      "  처리 중: 1701-1736/1736\n",
      "벡터 DB 저장 완료\n",
      "벡터 DB 생성 완료\n",
      "  - 저장 위치: D:\\data\\chroma_db\n",
      "  - 저장된 문서 수: 1736\n"
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "# 셀 12: Step 7 - 벡터 DB 생성\n",
    "# ===============================================\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "print(\"\\n[Step 7] 벡터 DB 생성\")\n",
    "\n",
    "# 기존 벡터 DB 디렉토리 완전 삭제\n",
    "if os.path.exists(PERSIST_DIRECTORY):\n",
    "    shutil.rmtree(PERSIST_DIRECTORY)\n",
    "    print(f\"기존 벡터 DB 삭제 완료: {PERSIST_DIRECTORY}\")\n",
    "\n",
    "# 새로운 벡터 DB 생성\n",
    "print(\"\\n[Step 7] 벡터 DB 생성 (새로 시작)\")\n",
    "vectorstore = create_vectorstore_safe(\n",
    "    chunks, embeddings, PERSIST_DIRECTORY, batch_size=50\n",
    ")\n",
    "\n",
    "# 임베딩 차원 확인\n",
    "test_embedding = embeddings.embed_query(\"테스트\")\n",
    "print(f\"현재 임베딩 차원: {len(test_embedding)}\")\n",
    "\n",
    "# 벡터 DB 생성\n",
    "try:\n",
    "    vectorstore = create_vectorstore_safe(\n",
    "        chunks, embeddings, PERSIST_DIRECTORY, batch_size=50\n",
    "    )\n",
    "    print(f\"벡터 DB 생성 완료\")\n",
    "    print(f\"  - 저장 위치: {PERSIST_DIRECTORY}\")\n",
    "    print(f\"  - 저장된 문서 수: {len(chunks)}\")\n",
    "except Exception as e:\n",
    "    print(f\"벡터 DB 생성 실패: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6b16555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 8] 검색 품질 평가\n",
      "\n",
      "======================================================================\n",
      "검색 품질 평가\n",
      "======================================================================\n",
      "\n",
      "질문: 이 문서의 주요 내용은 무엇인가요?\n",
      "--------------------------------------------------\n",
      "\n",
      "  결과 1:\n",
      "\n",
      "    거리 점수: 0.495\n",
      "    유사도: 75.2%\n",
      "    품질: 좋음\n",
      "    \n",
      "    섹션: 합병증\n",
      "    내용: 함. - 각 핵심질문은 2022년 진료지침에 사용했던 검색어, 검색식을 업데이트 및 보강함. - 29개 세부 소주제의 검색어, 검색식 및 검색결과는 파일 형태로 보관함. 2) 근거(진료지침)의 검색 ● \u0001근거문헌에 대해 집필그룹의 구성원이 문헌평가를 할 때 다음과 같은...\n",
      "\n",
      "  결과 2:\n",
      "\n",
      "    거리 점수: 0.495\n",
      "    유사도: 75.2%\n",
      "    품질: 좋음\n",
      "    \n",
      "    섹션: 합병증\n",
      "    내용: 함. - 각 핵심질문은 2022년 진료지침에 사용했던 검색어, 검색식을 업데이트 및 보강함. - 29개 세부 소주제의 검색어, 검색식 및 검색결과는 파일 형태로 보관함. 2) 근거(진료지침)의 검색 ● \u0001근거문헌에 대해 집필그룹의 구성원이 문헌평가를 할 때 다음과 같은...\n",
      "\n",
      "  결과 3:\n",
      "\n",
      "    거리 점수: 0.525\n",
      "    유사도: 73.7%\n",
      "    품질: 보통\n",
      "    \n",
      "    섹션: 일반\n",
      "    내용: . - 진료지침관련 색인단어는 다음의 조합으로 검색하였음 (Guideline* or Practice guideline* or Clinical practice guideline* or Recommendation* or Consensus) - 문헌검색은 전문사서 前) 제일...\n",
      "\n",
      "  [MMR 검색 - 다양성 확보]\n",
      "    1. [합병증] 함. - 각 핵심질문은 2022년 진료지침에 사용했던 검색어, 검색식을 업데이트 및 보강함. - 29개 세부 소주제의 검색어, 검색식 및 검색결...\n",
      "    2. [일반] ) 1.01 (0.84–1.21) 1.06 (0.82–1.37) NA NA NA NA NA NA All-cause mortality, HR (9...\n",
      "    3. [일반] ) 제일병원 의학도서실 전문사서 문헌검색 38 문헌검색 이영진 강동경희대학교병원 의학도서실 전문사서 문헌검색...\n",
      "\n",
      "질문: 당뇨병의 진단기준에 대해 알려주세요.\n",
      "--------------------------------------------------\n",
      "\n",
      "  결과 1:\n",
      "\n",
      "    거리 점수: 0.204\n",
      "    유사도: 89.8%\n",
      "    품질: 매우 좋음\n",
      "    \n",
      "    섹션: 진단\n",
      "    내용: 14 Clinical Practice Guidelines for Diabetes 증명되었으므로 당뇨병전단계 대상자의 선별은 매우 중요하다. 따라서 경구포도당내성검사를 통해 당뇨병 뿐만 아니라 내당능장애를 진단하는 것도 임상적으로 의미가 크다. 이상을 토대로 한 한국인의...\n",
      "\n",
      "  결과 2:\n",
      "\n",
      "    거리 점수: 0.204\n",
      "    유사도: 89.8%\n",
      "    품질: 매우 좋음\n",
      "    \n",
      "    섹션: 진단\n",
      "    내용: 14 Clinical Practice Guidelines for Diabetes 증명되었으므로 당뇨병전단계 대상자의 선별은 매우 중요하다. 따라서 경구포도당내성검사를 통해 당뇨병 뿐만 아니라 내당능장애를 진단하는 것도 임상적으로 의미가 크다. 이상을 토대로 한 한국인의...\n",
      "\n",
      "  결과 3:\n",
      "\n",
      "    거리 점수: 0.207\n",
      "    유사도: 89.7%\n",
      "    품질: 매우 좋음\n",
      "    \n",
      "    섹션: 진단\n",
      "    내용: 11 Clinical Practice Guidelines for Diabetes 당뇨병 진단 및 분류 01...\n",
      "\n",
      "  [MMR 검색 - 다양성 확보]\n",
      "    1. [진단] 14 Clinical Practice Guidelines for Diabetes 증명되었으므로 당뇨병전단계 대상자의 선별은 매우 중요하다. 따라...\n",
      "    2. [진단] 11 Clinical Practice Guidelines for Diabetes 당뇨병 진단 및 분류 01...\n",
      "    3. [진단] . 당뇨병환자에서 오심과 구토를 동반한 위마비증상, 변비, 설사, 대변실금, 발기장애, 배뇨장애, 요 실금, 체간부와 안면부에 발한 또는 하지무...\n",
      "\n",
      "질문: 당뇨병의 운동요법은 어떤것이 있나요?\n",
      "--------------------------------------------------\n",
      "\n",
      "  결과 1:\n",
      "\n",
      "    거리 점수: 0.255\n",
      "    유사도: 87.3%\n",
      "    품질: 매우 좋음\n",
      "    \n",
      "    섹션: 운동요법\n",
      "    내용: 다. 당뇨병환자에게서 체중감소, 신체활동증가, 금주를 포함한 의학영양요법 등의 생활습관교정은 고중성지방혈증의 치료에 효과적이며 일부 지질 관리 14...\n",
      "\n",
      "  결과 2:\n",
      "\n",
      "    거리 점수: 0.255\n",
      "    유사도: 87.3%\n",
      "    품질: 매우 좋음\n",
      "    \n",
      "    섹션: 운동요법\n",
      "    내용: 다. 당뇨병환자에게서 체중감소, 신체활동증가, 금주를 포함한 의학영양요법 등의 생활습관교정은 고중성지방혈증의 치료에 효과적이며 일부 지질 관리 14...\n",
      "\n",
      "  결과 3:\n",
      "\n",
      "    거리 점수: 0.265\n",
      "    유사도: 86.8%\n",
      "    품질: 매우 좋음\n",
      "    \n",
      "    섹션: 운동요법\n",
      "    내용: 다. 2. 이득(편익) 규칙적인 운동은 혈당조절을 향상시키고 심혈관질환 위험을 감소시키며 체중감소에 기여한다[12]. 또한 당 뇨병의 고위험군에서는 당뇨병 예방효과가 있다[13]. 대표적인 유산소운동으로는 걷기, 자전거 타기, 조깅, 수영 등이 있고, 근력을 이용하여 ...\n",
      "\n",
      "  [MMR 검색 - 다양성 확보]\n",
      "    1. [운동요법] 다. 당뇨병환자에게서 체중감소, 신체활동증가, 금주를 포함한 의학영양요법 등의 생활습관교정은 고중성지방혈증의 치료에 효과적이며 일부 지질 관리 ...\n",
      "    2. [운동요법] 다. 중등도 혹은 장시간 운동 시 저혈당이 발생할 수 있으며, 고강도 운동 시에는 고혈당이 발생할 수 있다. 혈당이 높은 환자에게서는 혈 당과 ...\n",
      "    3. [진단] . 당뇨병환자에서 오심과 구토를 동반한 위마비증상, 변비, 설사, 대변실금, 발기장애, 배뇨장애, 요 실금, 체간부와 안면부에 발한 또는 하지무...\n",
      "\n",
      "전체 평균 거리 점수: 0.318\n",
      "\n",
      "    거리 점수: 0.318\n",
      "    유사도: 84.1%\n",
      "    품질: 좋음\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "# 셀 13: Step 8 - 검색 품질 평가\n",
    "# ===============================================\n",
    "print(\"\\n[Step 8] 검색 품질 평가\")\n",
    "search_results = evaluate_search_quality(vectorstore, test_queries)\n",
    "\n",
    "# 평균 점수 계산\n",
    "if search_results:\n",
    "    avg_score = sum(r[\"top_score\"] for r in search_results if r[\"top_score\"]) / len(\n",
    "        search_results\n",
    "    )\n",
    "    print(f\"\\n전체 평균 거리 점수: {avg_score:.3f}\")\n",
    "    print(interpret_chroma_score(avg_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "752f4bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 9] 실험 결과 저장\n",
      "실험 결과 저장 완료: D:\\data\\rag_experiment_20251201_175820.json\n"
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "# 셀 14: Step 9 - 실험 결과 저장\n",
    "# ===============================================\n",
    "print(\"\\n[Step 9] 실험 결과 저장\")\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "experiment_results = {\n",
    "    \"experiment_info\": {\n",
    "        \"timestamp\": timestamp,\n",
    "        \"notebook\": \"02_RAG_01_Data indexing_v2.ipynb\",\n",
    "        \"purpose\": \"2주차 과제 - 한국어 의료 PDF RAG 시스템\",\n",
    "    },\n",
    "    \"data_statistics\": {\n",
    "        \"total_pages\": len(documents),\n",
    "        \"total_chunks\": len(chunks),\n",
    "        \"avg_chunk_size\": sum(len(c.page_content) for c in chunks) / len(chunks),\n",
    "    },\n",
    "    \"chunking_strategy\": best_strategy,\n",
    "    \"embedding_model\": EMBEDDING_TYPE,\n",
    "    \"section_distribution\": section_distribution,\n",
    "    \"vector_db\": {\"type\": \"Chroma\", \"persist_directory\": PERSIST_DIRECTORY},\n",
    "}\n",
    "\n",
    "output_path = Path(PDF_PATH) / f\"rag_experiment_{timestamp}.json\"\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(experiment_results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"실험 결과 저장 완료: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e53cea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "추가 검색 테스트 함수 준비 완료\n",
      "사용법: search_and_interpret('검색할 내용')\n"
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "# 셀 16: 추가 검색 테스트 함수\n",
    "# ===============================================\n",
    "def search_and_interpret(query):\n",
    "    \"\"\"검색 실행 및 결과 해석\"\"\"\n",
    "    results = vectorstore.similarity_search_with_score(query, k=3)\n",
    "\n",
    "    print(f\"\\n질문: {query}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    for i, (doc, score) in enumerate(results, 1):\n",
    "        print(f\"\\n결과 {i}:\")\n",
    "        print(interpret_chroma_score(score))\n",
    "        print(f\"섹션: {doc.metadata.get('section_kr', 'N/A')}\")\n",
    "        print(f\"내용: {doc.page_content[:200]}...\")\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# 테스트 예시\n",
    "print(\"추가 검색 테스트 함수 준비 완료\")\n",
    "print(\"사용법: search_and_interpret('검색할 내용')\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
